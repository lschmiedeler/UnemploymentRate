{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataCollection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1BKU7TojiHf0bQgYOBqDFzL6WvTfne-yO","authorship_tag":"ABX9TyPvEJqzB0Q5mRat2tgsSmVb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Collection"],"metadata":{"id":"6yyXebl3swBb"}},{"cell_type":"code","metadata":{"id":"d5SlS05jKZ7O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639839396368,"user_tz":360,"elapsed":3530,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"3c814aa8-9e4c-43e9-e72b-8918d2b7e7d0"},"source":["pip install full-fred"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: full-fred in /usr/local/lib/python3.7/dist-packages (0.0.9a3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from full-fred) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from full-fred) (1.1.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->full-fred) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->full-fred) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->full-fred) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->full-fred) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->full-fred) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->full-fred) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->full-fred) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->full-fred) (2.10)\n"]}]},{"cell_type":"code","metadata":{"id":"jxCYTshdbL47"},"source":["import pandas as pd\n","import numpy as np\n","from full_fred.fred import Fred\n","from datetime import datetime\n","from time import sleep"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpprEYE_tuhW"},"source":["fred = Fred('drive/MyDrive/Machine Learning Project/key.txt') # key.txt contains a valid FRED API key"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download the feature time series from FRED and export them to Google Drive in five separate csv files.  Put each time series is the csv file corresponding to its FRED category."],"metadata":{"id":"xXSWrD7esY6L"}},{"cell_type":"code","metadata":{"id":"F-Rb4ZWbavIz"},"source":["def test_duplicate_series(data, new_data):\n","  data_columns = data.columns\n","  new_data_columns = new_data.columns\n","  for column in data_columns:\n","    if column in new_data_columns and column != 'date':\n","      return True\n","  return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmE6lV0ReHNX"},"source":["def find_series(id, categories):\n","  global data\n","  if len(categories) == 0: # base case\n","    try:\n","      category_series = fred.get_series_in_a_category(id)['seriess']\n","    except KeyError as error:\n","      sleep(sleep_time)\n","      category_series = fred.get_series_in_a_category(id)['seriess']\n","    new_data = pd.DataFrame()\n","    for j in range(len(category_series)):\n","      id = category_series[j]['id']\n","      title = category_series[j]['title']\n","      frequency = category_series[j]['frequency_short']\n","      start_date = datetime.strptime(category_series[j]['observation_start'], '%Y-%m-%d')\n","      end_date = datetime.strptime(category_series[j]['observation_end'], '%Y-%m-%d')\n","      if (title.find('(DISCONTINUED)') == -1 and start_date <= min_date and end_date >= max_date and frequency in ('D', 'W', 'M')):\n","        try:\n","          series = (fred.get_series_df(series_id = id, frequency = \"m\"))[['date', 'value']]\n","        except KeyError as error:\n","          sleep(sleep_time)\n","          series = (fred.get_series_df(series_id = id, frequency = \"m\"))[['date', 'value']]\n","        for i in range(len(series)):\n","          series = series.copy()\n","          series.loc[i, 'date'] = datetime.strptime(series['date'][i], '%Y-%m-%d')\n","        series = series[series.date >= min_date]\n","        series = series[series.date <= max_date]\n","        if (series['value'].isin(['.'])).sum() == 0:\n","          series.columns = ['date', id]\n","          if len(new_data.columns) == 0:\n","            new_data = series\n","          else:\n","            new_data = new_data.merge(series, on = 'date')\n","    return new_data\n","  else: # recursive step\n","    for i in range(len(categories)):\n","      name = categories[i]['name']\n","      id = categories[i]['id']\n","      try:\n","        new_categories = fred.get_child_categories(id)['categories']\n","      except KeyError as error:\n","        sleep(sleep_time)\n","        new_categories = fred.get_child_categories(id)['categories']\n","      new_data = find_series(id, new_categories)\n","      if len(data.columns) == 0 and len(new_data.columns) > 0:\n","        data = new_data\n","      elif len(data.columns) > 0 and len(new_data.columns) > 0:\n","        if test_duplicate_series(data, new_data) == False:\n","          data = data.merge(new_data, on = 'date')\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLfmLHHBYZGD"},"source":["def save_series(id, categories, file_path):\n","  global data\n","  data = pd.DataFrame()\n","  df = find_series(id, categories)\n","  df.to_csv(file_path, index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpLrd8eFf6a2"},"source":["data = pd.DataFrame()\n","sleep_time = 100\n","min_date = datetime.strptime('1960-01-01', '%Y-%m-%d')\n","max_date = datetime.strptime('2020-12-31', '%Y-%m-%d')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"698dbLxaHdRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637951772714,"user_tz":360,"elapsed":705341,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"297a6623-ae8c-43ad-af4a-6edd46705c0f"},"source":["# 11m\n","save_series(32991, fred.get_child_categories(32991)['categories'],\n","            'drive/MyDrive/Machine Learning Project/data/MoneyBankingAndFinance.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Message: Too Many Requests.  Exceeded Rate Limit\n","Error Message: Too Many Requests.  Exceeded Rate Limit\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Utbxj2oxaCti","executionInfo":{"status":"ok","timestamp":1637951038183,"user_tz":360,"elapsed":302566,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"480641db-2637-40de-e3d5-b74e51e33a31"},"source":["# 5m 2s\n","save_series(10, fred.get_child_categories(10)['categories'][1:],\n","            'drive/MyDrive/Machine Learning Project/data/PopulationEmploymentAndLaborMarkets.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Message: Too Many Requests.  Exceeded Rate Limit\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXkrnPCyaDEY","executionInfo":{"status":"ok","timestamp":1637950462642,"user_tz":360,"elapsed":345780,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"11ddc8eb-7c57-4a4e-a758-e23ce6a4c7ad"},"source":["# 5m 45s\n","save_series(32992, fred.get_child_categories(32992)['categories'],\n","            'drive/MyDrive/Machine Learning Project/data/NationalAccounts.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Message: Too Many Requests.  Exceeded Rate Limit\n"]}]},{"cell_type":"code","metadata":{"id":"FUDLJY5OHovo"},"source":["# 2m 26s\n","save_series(1, fred.get_child_categories(1)['categories'],\n","            'drive/MyDrive/Machine Learning Project/data/ProductionAndBusinessActivity.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XmgvfM3mf8qn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637957116108,"user_tz":360,"elapsed":848205,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"4c2e4e56-dc92-4a0d-dfaf-bda984bed054"},"source":["# 14m\n","save_series(32455, fred.get_child_categories(32455)['categories'],\n","            'drive/MyDrive/Machine Learning Project/data/Prices.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Message: Too Many Requests.  Exceeded Rate Limit\n","Error Message: Too Many Requests.  Exceeded Rate Limit\n"]}]},{"cell_type":"markdown","source":["Import the five csv files containg the feature time series from Google Drive and merge them into one data frame."],"metadata":{"id":"Za42w1QRsqWK"}},{"cell_type":"code","metadata":{"id":"5tAXjvQ9foA-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639838287083,"user_tz":360,"elapsed":4359,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"22d79e6d-c055-445c-a00b-659fca3ab758"},"source":["df_mbf = pd.read_csv('drive/MyDrive/Machine Learning Project/data/MoneyBankingAndFinance.csv')\n","print(df_mbf.head())\n","df_pel = pd.read_csv('drive/MyDrive/Machine Learning Project/data/PopulationEmploymentAndLaborMarkets.csv')\n","print(df_pel.head())\n","df_na = pd.read_csv('drive/MyDrive/Machine Learning Project/data/NationalAccounts.csv')\n","print(df_na.head())\n","df_pba = pd.read_csv('drive/MyDrive/Machine Learning Project/data/ProductionAndBusinessActivity.csv')\n","print(df_pba.head())\n","df_prices = pd.read_csv('drive/MyDrive/Machine Learning Project/data/Prices.csv')\n","print(df_prices.head())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                  date   AAA   BAA  ...   TOTALSL  TOTALSLAR  TOTALTCU\n","0  1960-01-01 00:00:00  4.61  5.34  ...  56.01558       0.10     2.923\n","1  1960-02-01 00:00:00  4.56  5.34  ...  56.36463       7.48     2.850\n","2  1960-03-01 00:00:00  4.49  5.25  ...  56.86288      10.61     2.810\n","3  1960-04-01 00:00:00  4.45  5.20  ...  57.71140      17.91     2.963\n","4  1960-05-01 00:00:00  4.46  5.28  ...  57.95103       4.98     2.867\n","\n","[5 rows x 109 columns]\n","                  date  PAYEMS  PAYNSA  ...  CEU9093161101  CEU9093200001  USGOVT\n","0  1960-01-01 00:00:00   54274   53448  ...         2350.3         2161.7    8307\n","1  1960-02-01 00:00:00   54513   53422  ...         2380.0         2170.0    8326\n","2  1960-03-01 00:00:00   54454   53494  ...         2374.7         2182.3    8525\n","3  1960-04-01 00:00:00   54813   54285  ...         2364.6         2192.4    8534\n","4  1960-05-01 00:00:00   54475   54349  ...         2351.2         2213.8    8432\n","\n","[5 rows x 158 columns]\n","                  date  B039RC1M027SBEA  ...  MVMTD027MNFRBDAL  MVPHGFD027MNFRBDAL\n","0  1960-01-01 00:00:00              9.2  ...             179.7               200.5\n","1  1960-02-01 00:00:00              9.3  ...             179.8               201.0\n","2  1960-03-01 00:00:00              9.3  ...             178.8               200.0\n","3  1960-04-01 00:00:00              9.3  ...             180.4               200.9\n","4  1960-05-01 00:00:00              9.3  ...             180.6               200.5\n","\n","[5 rows x 38 columns]\n","                  date  GBRREC  GBRRECD  ...  HOUSTNSA  SHTNSAUS  SHTSAUS\n","0  1960-01-01 00:00:00     0.0        0  ...      86.0       7.0    114.0\n","1  1960-02-01 00:00:00     0.0        0  ...      90.7       9.0    116.0\n","2  1960-03-01 00:00:00     1.0        1  ...      90.5       9.0    104.0\n","3  1960-04-01 00:00:00     1.0        1  ...     123.0       9.0     96.0\n","4  1960-05-01 00:00:00     1.0        1  ...     130.2      11.0    111.0\n","\n","[5 rows x 53 columns]\n","                  date  CPIUFDNS  ...  PCU22112222112242  PCU22112222112243\n","0  1960-01-01 00:00:00      29.5  ...               26.2               17.6\n","1  1960-02-01 00:00:00      29.4  ...               26.2               17.8\n","2  1960-03-01 00:00:00      29.5  ...               26.2               17.8\n","3  1960-04-01 00:00:00      30.0  ...               26.2               17.8\n","4  1960-05-01 00:00:00      30.0  ...               26.2               17.8\n","\n","[5 rows x 447 columns]\n"]}]},{"cell_type":"code","metadata":{"id":"se9TfIHVZQYu"},"source":["def merge_dfs(dfs):\n","  df_all = pd.DataFrame()\n","  for i in range(len(dfs)):\n","    if i == 0:\n","      df_all = dfs[i]\n","    else:\n","      df_all = df_all.merge(dfs[i], on = 'date')\n","  return df_all"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d4-uv1QeZ8ll"},"source":["df = merge_dfs([df_mbf, df_pel, df_na, df_pba, df_prices])\n","\n","for i in range(len(df['date'])):\n","  df.loc[i, 'date'] = datetime.strptime(df['date'][i].split()[0], '%Y-%m-%d')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download the two response time series from FRED (unemployment rate and change in unemployment rate) and add them to the data frame containing the feature time series."],"metadata":{"id":"iVfxdYQutCMo"}},{"cell_type":"code","metadata":{"id":"yv69E8XIxo2T"},"source":["unrate_df = fred.get_series_df('UNRATE', observation_start = '1960-01-01', observation_end = '2020-12-01')[['date', 'value']]\n","\n","unrate_df = unrate_df.copy()\n","for i in range(len(unrate_df['date'])):\n","  unrate_df.loc[i, 'date'] = datetime.strptime(unrate_df['date'][i], '%Y-%m-%d')\n","\n","for i in range(len(unrate_df['value'])):\n","  unrate_df.loc[i, 'value'] = float(unrate_df['value'][i])\n","unrate_df['value'] = unrate_df['value'].astype(np.float)\n","\n","unrate_df.columns = ['date', 'UNRATE']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_fLxdXvKcotS"},"source":["unrate_chg_df = fred.get_series_df('UNRATE', units = 'chg', observation_start = '1960-01-01', observation_end = '2020-12-01')[['date', 'value']]\n","\n","unrate_chg_df = unrate_chg_df.copy()\n","for i in range(len(unrate_chg_df['date'])):\n","  unrate_chg_df.loc[i, 'date'] = datetime.strptime(unrate_chg_df['date'][i], '%Y-%m-%d')\n","\n","for i in range(len(unrate_chg_df['value'])):\n","  unrate_chg_df.loc[i, 'value'] = float(unrate_chg_df['value'][i])\n","unrate_chg_df['value'] = (unrate_chg_df['value'] > 0).astype(np.int)\n","\n","unrate_chg_df.columns = ['date', 'UNRATECHG']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtAL9za4yLTA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639838308577,"user_tz":360,"elapsed":326,"user":{"displayName":"Lauren Schmiedeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00767559766651914145"}},"outputId":"544d8250-618b-4960-e79b-e90acb99ee6d"},"source":["df = df.merge(unrate_df, on = 'date')\n","df = df.merge(unrate_chg_df, on = 'date')\n","print(df.head())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                  date   AAA   BAA  ...  PCU22112222112243  UNRATE  UNRATECHG\n","0  1960-01-01 00:00:00  4.61  5.34  ...               17.6     5.2          0\n","1  1960-02-01 00:00:00  4.56  5.34  ...               17.8     4.8          0\n","2  1960-03-01 00:00:00  4.49  5.25  ...               17.8     5.4          1\n","3  1960-04-01 00:00:00  4.45  5.20  ...               17.8     5.2          0\n","4  1960-05-01 00:00:00  4.46  5.28  ...               17.8     5.1          0\n","\n","[5 rows x 803 columns]\n"]}]},{"cell_type":"markdown","source":["Export the full data frame to Google Drive."],"metadata":{"id":"Q4tLE4ax02E_"}},{"cell_type":"code","source":["df.to_csv('drive/MyDrive/Machine Learning Project/data/AllData.csv', index = False)"],"metadata":{"id":"mJMqcti91fTz"},"execution_count":null,"outputs":[]}]}